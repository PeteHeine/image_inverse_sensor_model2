<launch>

	<!-- Use perspektive mapping to transform a detection image to an inverse sensor model -->
	<node type="image2ism.py" name="image2ismSS" pkg="image_inverse_sensor_model" respawn="true" output="screen">
		
		<!-- Add multiple topics by seperating them by a space in topicIns-->
		<param name="topicIns" value="/det/Multisense/semantic_segmentation/grass /det/Multisense/semantic_segmentation/ground /det/Multisense/semantic_segmentation/human /det/Multisense/semantic_segmentation/shelterbelt /det/Multisense/semantic_segmentation/unknown /det/Multisense/semantic_segmentation/vehicle /det/Multisense/semantic_segmentation/water" /> 
		
		<param name="cam_FOV" value="0.78345" />	<!-- Half DiagonalFOV 1.5669/2 = 0.78345. This is found using calibration found in Demo_CalibrationCheckerBoardMiniSensorKit.m -->
		<param name="imageWidth" value="512" />  	<!-- Half of 1024 is selected = 512 -->
		<param name="imageHeight" value="217" />	<!-- Half of 544 is selected = 217 -->
		<param name="grid_resolution" value="0.5" />

		<param name="cam_xTranslation" value="0.2038" /> 
		<param name="cam_yTranslation" value="0.255" />
		<param name="cam_zTranslation" value="2.056" />
		<param name="cam_pitch" value="0.1963" />  
		<param name="cam_yaw" value="0.0" />
	</node>


	<!-- Showing image detection for each object class --> 
	<node name="image_view0" pkg="image_view" type="image_view" respawn="false" output="screen">
			<remap from="image" to="/det/Multisense/semantic_segmentation/grass"/>
			<param name="autosize" value="false" />
			<param name="window_name" value="grass" />
	</node>

</launch>
